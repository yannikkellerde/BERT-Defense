# A Bayesian approach at shielding against adversarial attacks on natural language

## TODO
- [x] Implement Phonetic attacks
- [x] Add swaps to levenshtein distance
- [x] Give the project some resonable structure / remove the hacky stuff for shared task
- [x] Add BERT version that can handle probability distributions over words as inputs.
- [x] Develop easy to use api for adversarial attacks.
- [ ] Evaluate baseline https://github.com/danishpruthi/Adversarial-Misspellings
- [ ] Evaluation Metric for shielding (Direct: BLEU, ROUGE, MOVER; Outgoing: STS-B SNLI etc.)
- [ ] Use evaluation Metrics to find best hyperparameters
- [ ] Find information about human text similarity clues (ask psychologists and/or read papers)
- [ ] Maybe make an experiment about humans handeling adversarial attacks.
- [ ] Handle random shuffeling, reversed words and potentially even more human similarity clues.
- [ ] Find a way to handle abnormal word segmentations (*Working on it*).
- [ ] Write the paper